{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe6e8b87",
   "metadata": {},
   "source": [
    "# XGBoost on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01cce02",
   "metadata": {},
   "source": [
    "### Methods & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c992df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import joblib\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:75% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_rows', 250)\n",
    "pd.set_option('display.min_rows', 25)\n",
    "\n",
    "####\n",
    "# Plays sinus\n",
    "def playSound():\n",
    "    from IPython.lib.display import Audio\n",
    "    framerate = 4410\n",
    "    play_time_seconds = 3\n",
    "\n",
    "    t = np.linspace(0, play_time_seconds, framerate*play_time_seconds)\n",
    "    audio_data = np.sin(2*np.pi*300*t) + np.sin(2*np.pi*200*t)\n",
    "    return Audio(audio_data, rate=framerate, autoplay=True) # plays 3sec sound, when done\n",
    "    \n",
    "\n",
    "####\n",
    "# prints memory usage\n",
    "def show_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB\\n'.format(start_mem))\n",
    "    return\n",
    "\n",
    "####\n",
    "# seperates features from label (y must be last column)\n",
    "def sep_X_y(df_train, df_test):\n",
    "    X_train = df_train.iloc[:,0:-1] # extracts all rows [:] and columns from 0 to next-to-last [0:-1]\n",
    "    y_train = df_train.iloc[:,-1] # extracts all rows [:] and only last column [-1]\n",
    "    X_test = df_test.iloc[:,0:-1]\n",
    "    y_test = df_test.iloc[:,-1]\n",
    "    \n",
    "    return [X_train, y_train, X_test, y_test]\n",
    "\n",
    "####\n",
    "# split training and test set from given dataframe with dates as boundaries\n",
    "def dt_train_test_split(df, dt_start_train, dt_end_train, dt_start_test, dt_end_test):\n",
    "    print('Splitting dataframe...\\n')\n",
    "    # get indices from desired boundaries\n",
    "    idx_start_train = df.date.searchsorted(pd.to_datetime(dt_start_train), side='left') # list needs to be sorted already for searchsorted\n",
    "    idx_end_train = df.date.searchsorted(pd.to_datetime(dt_end_train) + pd.Timedelta(days=1), side='left')\n",
    "    idx_start_test = df.date.searchsorted(pd.to_datetime(dt_start_test), side='left')\n",
    "    idx_end_test = df.date.searchsorted(pd.to_datetime(dt_end_test) + pd.Timedelta(days=1), side='left')\n",
    "    \n",
    "    train = df.iloc[idx_start_train:idx_end_train]\n",
    "    test = df.iloc[idx_start_test:idx_end_test]\n",
    "    \n",
    "    train.drop(columns=['date'], axis=0, inplace=True)\n",
    "    test.drop(columns=['date'], axis=0, inplace=True)\n",
    "    \n",
    "    return sep_X_y(train, test)\n",
    "\n",
    "####\n",
    "# split training and test set from given dataframe with month as boundaries\n",
    "def mth_train_test_split(df, mth_start_train, mth_end_train, mth_start_test, mth_end_test):\n",
    "    print('Splitting dataframe...\\n')\n",
    "    \n",
    "    # get indices from desired boundaries\n",
    "    idx_start_train = df.month.searchsorted(mth_start_train, side='left') # list needs to be sorted already for searchsorted\n",
    "    idx_end_train = df.month.searchsorted(mth_end_train + 1, side='left')\n",
    "    idx_start_test = df.month.searchsorted(mth_start_test, side='left')\n",
    "    idx_end_test = df.month.searchsorted(mth_end_test + 1, side='left')\n",
    "    \n",
    "    train = df.iloc[idx_start_train:idx_end_train]\n",
    "    test = df.iloc[idx_start_test:idx_end_test]\n",
    "    \n",
    "    #train.drop(columns=['date'], axis=0, inplace=True)\n",
    "    #test.drop(columns=['date'], axis=0, inplace=True)\n",
    "    \n",
    "    return sep_X_y(train, test)\n",
    "\n",
    "####\n",
    "# trains XGB model (classifier)\n",
    "def train_xgb(X, y):\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    \n",
    "    print('Fitting model...\\n')\n",
    "    model = XGBClassifier(tree_method='gpu_hist', gpu_id=0)\n",
    "    fitted_model = model.fit(X_train, y_train)\n",
    "    \n",
    "    print('Plotting feature importance for \"gain\". Do not rely on that.\\n')\n",
    "    print('https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27\\n')\n",
    "    xgb.plot_importance(model, importance_type='gain')\n",
    "    plt.show()\n",
    "    \n",
    "    # GRAPHVIZ (software + pip package) needed for tree plotting\n",
    "    #fig, ax = plt.subplots(figsize=(30, 30))\n",
    "    #xgb.plot_tree(model, num_trees=0, ax=ax, rankdir='LR')\n",
    "    #plt.show()\n",
    "    \n",
    "    return fitted_model\n",
    "\n",
    "####\n",
    "# predicts labels of training and test with given model\n",
    "def predict_values(model, X_train, y_train, X_test, y_test):\n",
    "    print('Predicting values...\\n')\n",
    "    # predict y values\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # get accuracies\n",
    "    model_train = accuracy_score(y_train, y_train_pred)\n",
    "    model_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    # print info about accuracies\n",
    "    print(f'\\n XGboost train/test accuracies: '\n",
    "         f'{model_train:.3f}/{model_test:.3f}')\n",
    "    \n",
    "    # return predicted values\n",
    "    return [y_train_pred, y_test_pred]\n",
    "\n",
    "####\n",
    "# concatenates prediction with actual target for evaluation\n",
    "def evaluate_pred(X, y, y_pred):\n",
    "    # create dataframe from test-prediction with index from X_test\n",
    "    df_y_pred = pd.DataFrame(y_pred, columns=['nextBuyIn_pred'], index=X.index, dtype=np.int8)\n",
    "\n",
    "    # concatenate X, y, y_pred (put columns next to each other)\n",
    "    df_eval = pd.concat([X, y, df_y_pred], axis=1)\n",
    "    \n",
    "    return df_eval\n",
    "\n",
    "####\n",
    "# executes all needed functions of the above with given training and test data and provided train method\n",
    "def execute_pipeline(train_method, df, list_of_four_df_boundaries):\n",
    "    b = list_of_four_df_boundaries\n",
    "    # split dataframe in train/test and X/y\n",
    "    X_train, y_train, X_test, y_test = dt_train_test_split(df, b[0], b[1], b[2], b[3])\n",
    "    \n",
    "    #train model\n",
    "    model = train_method(X_train, y_train)    \n",
    "    \n",
    "    # make predictions\n",
    "    pred_train, pred_test = predict_values(model, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print('\\nExecuted pipeline.\\nEvaluate with \"evaluate_pred(X, y, y_pred)\"\\n')\n",
    "    return [pred_train, pred_test, X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "639f3776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 244725866 entries, 0 to 244725865\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   userID      uint16\n",
      " 1   itemID      uint16\n",
      " 2   brand       int16 \n",
      " 3   feature_1   int8  \n",
      " 4   feature_2   uint8 \n",
      " 5   feature_3   int16 \n",
      " 6   feature_4   int8  \n",
      " 7   feature_5   int16 \n",
      " 8   order       uint8 \n",
      " 9   year        uint16\n",
      " 10  month       uint8 \n",
      " 11  dayofmonth  uint8 \n",
      " 12  weekofyear  uint8 \n",
      " 13  week        uint8 \n",
      "dtypes: int16(3), int8(2), uint16(3), uint8(6)\n",
      "memory usage: 6.4 GB\n",
      "CPU times: total: 49.5 s\n",
      "Wall time: 9.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#TODO: IMPORT ORDER! \n",
    "\n",
    "path = r'C:\\Users\\LEAND\\Coding\\Jupyter Notebooks\\csv\\220621_01_everyCombinationPerDay_basicFeatures_labeled.parquet'\n",
    "df = pd.read_parquet(path, engine='pyarrow')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ff9a45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#savepath = r'C:\\Users\\LEAND\\Coding\\Jupyter Notebooks\\csv\\220621_01_everyCombinationPerDay_basicFeatures_labeled.parquet'\n",
    "#df_complete.to_parquet(savepath, engine='pyarrow', compression='snappy', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f229ef9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataframe...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = mth_train_test_split(df, 6, 10, 11, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "185e24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_Xtrain = r'C:\\Users\\LEAND\\Coding\\Jupyter Notebooks\\csv\\220621_02_everyCombinationPerDay_basicFeatures_labeled_XTrain.parquet'\n",
    "save_Xtest = r'C:\\Users\\LEAND\\Coding\\Jupyter Notebooks\\csv\\220621_02_everyCombinationPerDay_basicFeatures_labeled_XTest.parquet'\n",
    "save_ytrain = r'C:\\Users\\LEAND\\Coding\\Jupyter Notebooks\\csv\\220621_02_everyCombinationPerDay_basicFeatures_labeled_yTrain.parquet'\n",
    "save_ytest = r'C:\\Users\\LEAND\\Coding\\Jupyter Notebooks\\csv\\220621_02_everyCombinationPerDay_basicFeatures_labeled_yTest.parquet'\n",
    "\n",
    "X_train.to_parquet(save_Xtrain, engine='pyarrow', compression='snappy', index=None)\n",
    "pd.DataFrame(y_train).to_parquet(save_ytrain, engine='pyarrow', compression='snappy', index=None)\n",
    "X_test.to_parquet(save_Xtest, engine='pyarrow', compression='snappy', index=None)\n",
    "pd.DataFrame(y_test).to_parquet(save_ytest, engine='pyarrow', compression='snappy', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "147184c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1763"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d125ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead5d543",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae906709",
   "metadata": {},
   "source": [
    "# Predicting Weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a3dddf",
   "metadata": {},
   "source": [
    "## Training & Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57002dd",
   "metadata": {},
   "source": [
    "Pipeline needs training method, dataframe and dates to split dataframe in training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95faf968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mtrain_xgb\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFitting model...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     98\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBClassifier(tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_hist\u001b[39m\u001b[38;5;124m'\u001b[39m, gpu_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 99\u001b[0m fitted_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlotting feature importance for \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgain\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Do not rely on that.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conda-pip-env\\lib\\site-packages\\xgboost\\core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    531\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conda-pip-env\\lib\\site-packages\\xgboost\\sklearn.py:1382\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1377\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\n\u001b[0;32m   1379\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(\n\u001b[0;32m   1380\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1381\u001b[0m )\n\u001b[1;32m-> 1382\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_evaluation_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1395\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_qid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_dmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mDMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnthread\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1401\u001b[0m     params,\n\u001b[0;32m   1402\u001b[0m     train_dmatrix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1411\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1412\u001b[0m )\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conda-pip-env\\lib\\site-packages\\xgboost\\sklearn.py:401\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_evaluation_matrices\u001b[39m(\n\u001b[0;32m    382\u001b[0m     missing: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[0;32m    383\u001b[0m     X: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m     enable_categorical: \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m    397\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;124;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the way.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 401\u001b[0m     train_dmatrix \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dmatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    413\u001b[0m     n_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conda-pip-env\\lib\\site-packages\\xgboost\\sklearn.py:1396\u001b[0m, in \u001b[0;36mXGBClassifier.fit.<locals>.<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m   1377\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\n\u001b[0;32m   1379\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(\n\u001b[0;32m   1380\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1381\u001b[0m )\n\u001b[0;32m   1382\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1383\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1384\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1385\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   1386\u001b[0m     group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1387\u001b[0m     qid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1388\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1389\u001b[0m     base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1390\u001b[0m     feature_weights\u001b[38;5;241m=\u001b[39mfeature_weights,\n\u001b[0;32m   1391\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39meval_set,\n\u001b[0;32m   1392\u001b[0m     sample_weight_eval_set\u001b[38;5;241m=\u001b[39msample_weight_eval_set,\n\u001b[0;32m   1393\u001b[0m     base_margin_eval_set\u001b[38;5;241m=\u001b[39mbase_margin_eval_set,\n\u001b[0;32m   1394\u001b[0m     eval_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1395\u001b[0m     eval_qid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m-> 1396\u001b[0m     create_dmatrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: DMatrix(nthread\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[0;32m   1397\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_categorical,\n\u001b[0;32m   1398\u001b[0m )\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1401\u001b[0m     params,\n\u001b[0;32m   1402\u001b[0m     train_dmatrix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1411\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1412\u001b[0m )\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conda-pip-env\\lib\\site-packages\\xgboost\\core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    531\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conda-pip-env\\lib\\site-packages\\xgboost\\core.py:643\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 643\u001b[0m handle, feature_names, feature_types \u001b[38;5;241m=\u001b[39m \u001b[43mdispatch_data_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnthread\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m handle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conda-pip-env\\lib\\site-packages\\xgboost\\data.py:896\u001b[0m, in \u001b[0;36mdispatch_data_backend\u001b[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_tuple(data, missing, threads, feature_names, feature_types)\n\u001b[0;32m    895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_df(data):\n\u001b[1;32m--> 896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_from_pandas_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_series(data):\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_pandas_series(\n\u001b[0;32m    900\u001b[0m         data, missing, threads, enable_categorical, feature_names, feature_types\n\u001b[0;32m    901\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conda-pip-env\\lib\\site-packages\\xgboost\\data.py:348\u001b[0m, in \u001b[0;36m_from_pandas_df\u001b[1;34m(data, enable_categorical, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_pandas_df\u001b[39m(\n\u001b[0;32m    338\u001b[0m     data: DataFrame,\n\u001b[0;32m    339\u001b[0m     enable_categorical: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    343\u001b[0m     feature_types: Optional[List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m    344\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[ctypes\u001b[38;5;241m.\u001b[39mc_void_p, FeatureNames, Optional[List[\u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m    345\u001b[0m     data, feature_names, feature_types \u001b[38;5;241m=\u001b[39m _transform_pandas_df(\n\u001b[0;32m    346\u001b[0m         data, enable_categorical, feature_names, feature_types\n\u001b[0;32m    347\u001b[0m     )\n\u001b[1;32m--> 348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_from_numpy_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conda-pip-env\\lib\\site-packages\\xgboost\\data.py:184\u001b[0m, in \u001b[0;36m_from_numpy_array\u001b[1;34m(data, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    179\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(missing),\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnthread\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(nthread),\n\u001b[0;32m    182\u001b[0m }\n\u001b[0;32m    183\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(args), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 184\u001b[0m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGDMatrixCreateFromDense\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_array_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m handle, feature_names, feature_types\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conda-pip-env\\lib\\site-packages\\xgboost\\core.py:203\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: bad allocation"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = train_xgb(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e125d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train, pred_test = predict_values(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76785623",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d9b60",
   "metadata": {},
   "source": [
    "### train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c007b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_eval_train = evaluate_pred(X_train, y_train, pred_train)\n",
    "df_eval_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af92e914",
   "metadata": {},
   "source": [
    "### test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac0b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_test = evaluate_pred(X_test, y_test, pred_test)\n",
    "df_eval_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6082215e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rowcount = len(df_eval_test)\n",
    "should = len(df_eval_test.loc[(df_eval_test.nextBuyInWeeks != 0)])\n",
    "is_ = len(df_eval_test.loc[(df_eval_test.nextBuyInWeeks != 0) & (df_eval_test.nextBuyInWeeks == df_eval_test.nextBuyIn_pred)]) \n",
    "\n",
    "print(f'row count of set:\\t\\t\\t\\t\\t {rowcount}')\n",
    "print(f'rows where label is not 0:\\t\\t\\t\\t {should} \\t ({should/rowcount*100:.3f} % of all rows in set)')\n",
    "print(f'rows where label was predicted correctly AND not 0:\\t {is_} \\t ({is_/should*100:.3f} % of rows where label is actually not 0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49edaf3d",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
