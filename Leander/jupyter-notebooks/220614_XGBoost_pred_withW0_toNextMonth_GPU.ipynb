{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0751b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import gc\n",
    "import joblib\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_rows', 250)\n",
    "pd.set_option('display.min_rows', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c992df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB\\n'.format(start_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "639f3776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read csv\n",
    "csv_jun = r'C:\\Users\\LEAND\\Coding\\Jupyter Notebooks\\csv\\220613_01_dataset_w0-to-nxt-month_labeled_jun.csv'\n",
    "csv_jul = r'C:\\Users\\LEAND\\Coding\\Jupyter Notebooks\\csv\\220613_02_dataset_w0-to-nxt-month_labeled_jul.csv'\n",
    "csv_aug = r'C:\\Users\\LEAND\\Coding\\Jupyter Notebooks\\csv\\220613_03_dataset_w0-to-nxt-month_labeled_aug.csv'\n",
    "csv_sep = r'C:\\Users\\LEAND\\Coding\\Jupyter Notebooks\\csv\\220613_04_dataset_w0-to-nxt-month_labeled_sep.csv'\n",
    "csv_oct = r'C:\\Users\\LEAND\\Coding\\Jupyter Notebooks\\csv\\220613_05_dataset_w0-to-nxt-month_labeled_oct.csv'\n",
    "csv_nov = r'C:\\Users\\LEAND\\Coding\\Jupyter Notebooks\\csv\\220613_06_dataset_w0-to-nxt-month_labeled_nov.csv'\n",
    "csv_dec = r'C:\\Users\\LEAND\\Coding\\Jupyter Notebooks\\csv\\220613_07_dataset_w0-to-nxt-month_labeled_dec.csv'\n",
    "csv_jan = r'C:\\Users\\LEAND\\Coding\\Jupyter Notebooks\\csv\\220613_08_dataset_w0-to-nxt-month_labeled_jan.csv'\n",
    "\n",
    "csv_list = [csv_jun, csv_jul, csv_aug, csv_sep, csv_oct, csv_nov, csv_dec, csv_jan]\n",
    "\n",
    "columns = ['userID', \n",
    "           'itemID', \n",
    "           'order', \n",
    "           'brand', \n",
    "           'feature_1', \n",
    "           'feature_2', \n",
    "           'feature_3', \n",
    "           'feature_4', \n",
    "           'feature_5',\n",
    "           'categories', \n",
    "           'week']\n",
    "\n",
    "dtype = {'userID':np.uint32,\n",
    "          'itemID':np.uint32,\n",
    "          'order':np.uint8,\n",
    "          'brand':np.int16,\n",
    "          'feature_1':np.int8,\n",
    "          'feature_2':np.uint8,\n",
    "          'feature_3':np.int16,\n",
    "          'feature_4':np.int8,\n",
    "          'feature_5':np.int16,\n",
    "          'week':np.uint8}\n",
    "\n",
    "nov = pd.read_csv(csv_nov, usecols=columns, sep='|', dtype=dtype, nrows=None)\n",
    "dec = pd.read_csv(csv_dec, usecols=columns, sep='|', dtype=dtype, nrows=None)\n",
    "jan = pd.read_csv(csv_jun, usecols=columns, sep='|', dtype=dtype, nrows=None)\n",
    "\n",
    "train, train2 = train_test_split(pd.concat([nov, dec], axis=0), train_size=0.3, shuffle=True)\n",
    "test, test2 = train_test_split(jan, train_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f51f41",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b07a4851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    # convert string to list of integers in 'categories'\n",
    "    df[\"categories\"] = df[\"categories\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "    \n",
    "    # add fake row with all categories from 0 to 4299 to later have all columns in multi-hot-encoding\n",
    "    df.loc[len(df)] = [424242,424242,42, 42, 0, 0, 0, 0, 0, [cat for cat in range(0,4300)], 5]\n",
    "    df.index = df.index + 1  # add index\n",
    "    \n",
    "    # multi-hot-encode categories\n",
    "    cats = df[\"categories\"]\n",
    "    mlb = MultiLabelBinarizer(sparse_output=False) # Set to True if output binary array is desired in CSR sparse format\n",
    "    df_multi_hot = pd.DataFrame(mlb.fit_transform(cats), columns=mlb.classes_, index=df.index, dtype=np.int8).astype(pd.SparseDtype(np.uint8,0))\n",
    "    \n",
    "    # join new binarized columns with rest of dataframe\n",
    "    df = df.join(df_multi_hot, how='inner')\n",
    "    if (len(df[df.isnull().any(axis=1)]) > 0):\n",
    "        raise RuntimeError('Join of multi-hot-encoded categories probably created missing values.')\n",
    "    df.drop(df.tail(1).index,inplace=True) # drop fake row\n",
    "    \n",
    "    # drop list of categories, since it's not needed anymore\n",
    "    df.drop('categories', axis=1, inplace=True)\n",
    "    \n",
    "    # pop and append 'week' at end of dataframe\n",
    "    col = df.pop(\"week\")\n",
    "    df.insert(len(df.columns), col.name, col)\n",
    "    \n",
    "    print(df.info())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e2d4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "befd56a9",
   "metadata": {},
   "source": [
    "### Datatypes for XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed484f6f",
   "metadata": {},
   "source": [
    "XGBoost natively supports continuous data but not categorical data. In order to use categorical data with XGBoost, we have to use One-Hot-Encoding which converts a column of categorical values into muliple columns of binary values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e6f8b",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7df931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access \"X\" and \"y\" via split_X_y(df)[\"X\"] & split_X_y(df)[\"y\"]\n",
    "def split_X_y(df):\n",
    "    X = df.iloc[:,0:-1] # extracts all rows [:] and columns from 0 to next-to-last [0:-1]\n",
    "    y = df.iloc[:,-1] # extracts all rows [:] and only last column [-1]  \n",
    "    return {\"X\":X, \"y\":y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5226d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(X, y):\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    \n",
    "    classifier = XGBClassifier(tree_method='gpu_hist', gpu_id=0)\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77777e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgb(X, y):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07bf8275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_values(model, X_train, y_train, X_test, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # get accuracies\n",
    "    model_train = accuracy_score(y_train, y_train_pred)\n",
    "    model_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    print(f'\\n XGboost train/test accuracies: '\n",
    "         f'{model_train:.3f}/{model_test:.3f}')\n",
    "    \n",
    "    return {\"train_pred\":y_train_pred, \"test_pred\":y_test_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9292c09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pred(X, y, y_pred):\n",
    "    # create dataframe from test-prediction with index from X_test\n",
    "    df_y_pred = pd.DataFrame(y_pred, columns=['week_pred'], index=X.index, dtype=np.int8)\n",
    "\n",
    "    # concatenate X, y, y_pred (put columns next to each other)\n",
    "    df_eval = pd.concat([X, y, df_y_pred], axis=1)\n",
    "    \n",
    "    return df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4046e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_pipeline(train, test, train_method):\n",
    "    train_pre = preprocess_df(train)\n",
    "    test_pre  = preprocess_df(test)\n",
    "    \n",
    "    train_Xy = split_X_y(train_pre)\n",
    "    test_Xy = split_X_y(test_pre)\n",
    "    \n",
    "    X_train = train_Xy[\"X\"]\n",
    "    y_train = train_Xy[\"y\"]\n",
    "    X_test = test_Xy[\"X\"]\n",
    "    y_test = test_Xy[\"y\"]\n",
    "    \n",
    "    model = train_method(X_train, y_train)\n",
    "    prediction = predict_values(model, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    return evaluate_pred(X_test, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3854c2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "835dfdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 556286 entries, 4 to 778128\n",
      "Columns: 4310 entries, userID to week\n",
      "dtypes: Sparse[int32, 0](4300), int64(10)\n",
      "memory usage: 73.6 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38894 entries, 67619 to 1338\n",
      "Columns: 4310 entries, userID to week\n",
      "dtypes: Sparse[int32, 0](4300), int64(10)\n",
      "memory usage: 5.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_pre = preprocess_df(train)\n",
    "test_pre  = preprocess_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b741a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Xy = split_X_y(train_pre)\n",
    "test_Xy = split_X_y(test_pre)\n",
    "\n",
    "X_train = train_Xy[\"X\"]\n",
    "y_train = train_Xy[\"y\"]\n",
    "X_test = test_Xy[\"X\"]\n",
    "y_test = test_Xy[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67b6f6c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_Xy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_Xy' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "del train_Xy\n",
    "del test_Xy\n",
    "gc.collect()\n",
    "model = train_xgb(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa69269",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_values(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96472e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_pred(X_test, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49edaf3d",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
