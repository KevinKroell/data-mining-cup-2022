{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe6e8b87",
   "metadata": {},
   "source": [
    "# Model Comparison, no categories, with dates, including \"onetimers\"\n",
    "## Predicting the time difference to the next repurchase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01cce02",
   "metadata": {},
   "source": [
    "### Methods & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c992df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import joblib\n",
    "import hyperopt\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_rows', 250)\n",
    "pd.set_option('display.min_rows', 25)\n",
    "\n",
    "####\n",
    "# prints memory usage\n",
    "def show_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB\\n'.format(start_mem))\n",
    "    return\n",
    "\n",
    "####\n",
    "# seperates features from label (y must be last column)\n",
    "def sep_X_y(df_train, df_test):\n",
    "    X_train = df_train.iloc[:,0:-1] # extracts all rows [:] and columns from 0 to next-to-last [0:-1]\n",
    "    y_train = df_train.iloc[:,-1] # extracts all rows [:] and only last column [-1]\n",
    "    X_test = df_test.iloc[:,0:-1]\n",
    "    y_test = df_test.iloc[:,-1]\n",
    "    \n",
    "    return [X_train, y_train, X_test, y_test]\n",
    "\n",
    "####\n",
    "# split training and test set from given dataframe with dates as boundaries\n",
    "def dt_train_test_split(df, dt_start_train, dt_end_train, dt_start_test, dt_end_test):\n",
    "    print('Splitting dataframe...\\n')\n",
    "    # get indices from desired boundaries\n",
    "    idx_start_train = df.date.searchsorted(pd.to_datetime(dt_start_train), side='left') # list needs to be sorted already for searchsorted\n",
    "    idx_end_train = df.date.searchsorted(pd.to_datetime(dt_end_train) + pd.Timedelta(days=1), side='left')\n",
    "    idx_start_test = df.date.searchsorted(pd.to_datetime(dt_start_test), side='left')\n",
    "    idx_end_test = df.date.searchsorted(pd.to_datetime(dt_end_test) + pd.Timedelta(days=1), side='left')\n",
    "    \n",
    "    train = df.iloc[idx_start_train:idx_end_train]\n",
    "    test = df.iloc[idx_start_test:idx_end_test]\n",
    "    \n",
    "    train.drop(columns=['date'], axis=0, inplace=True)\n",
    "    test.drop(columns=['date'], axis=0, inplace=True)\n",
    "    \n",
    "    return sep_X_y(train, test)\n",
    "\n",
    "####\n",
    "# trains XGB model (classifier)\n",
    "def train_xgb(X, y):\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    \n",
    "    print('Fitting model...\\n')\n",
    "    model = XGBClassifier(tree_method='gpu_hist', gpu_id=0)\n",
    "    fitted_model = model.fit(X_train, y_train)\n",
    "    \n",
    "    print('Plotting feature importance for \"gain\". Do not rely on that.\\n')\n",
    "    print('https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27\\n')\n",
    "    xgb.plot_importance(model, importance_type='gain')\n",
    "    plt.show()\n",
    "    \n",
    "    # GRAPHVIZ (software + pip package) needed for tree plotting\n",
    "    #fig, ax = plt.subplots(figsize=(30, 30))\n",
    "    #xgb.plot_tree(model, num_trees=0, ax=ax, rankdir='LR')\n",
    "    #plt.show()\n",
    "    \n",
    "    return fitted_model\n",
    "\n",
    "####\n",
    "# predicts labels of training and test with given model\n",
    "def predict_values(model, X_train, y_train, X_test, y_test):\n",
    "    print('Predicting values...\\n')\n",
    "    # predict y values\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    \n",
    "    # get accuracies\n",
    "    model_train = accuracy_score(y_train, y_train_pred)\n",
    "    model_test = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #get precision\n",
    "    model_train_precision = precision_score(y_train, y_train_pred, average)\n",
    "    model_test_precision = precision_score(y_test, y_test_pred)\n",
    "    \"\"\"\n",
    "    # print info about accuracies\n",
    "    print(f'\\n XGboost train/test accuracies: '\n",
    "         f'{model_train:.3f}/{model_test:.3f}')\n",
    "    \n",
    "    # return predicted values\n",
    "    return [y_train_pred, y_test_pred]\n",
    "\n",
    "####\n",
    "# concatenates prediction with actual target for evaluation\n",
    "def evaluate_pred(X, y, y_pred):\n",
    "    # create dataframe from test-prediction with index from X_test\n",
    "    df_y_pred = pd.DataFrame(y_pred, columns=['nextBuyIn_pred'], index=X.index, dtype=np.int8)\n",
    "\n",
    "    # concatenate X, y, y_pred (put columns next to each other)\n",
    "    df_eval = pd.concat([X, y, df_y_pred], axis=1)\n",
    "    \n",
    "    return df_eval\n",
    "\n",
    "####\n",
    "# executes all needed functions of the above with given training and test data and provided train method\n",
    "def execute_pipeline(train_method, df, list_of_four_df_boundaries):\n",
    "    b = list_of_four_df_boundaries\n",
    "    # split dataframe in train/test and X/y\n",
    "    X_train, y_train, X_test, y_test = dt_train_test_split(df, b[0], b[1], b[2], b[3])\n",
    "    \n",
    "    #train model\n",
    "    model = train_method(X_train, y_train)    \n",
    "    \n",
    "    # make predictions\n",
    "    pred_train, pred_test = predict_values(model, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print('\\nExecuted pipeline.\\nEvaluate with \"evaluate_pred(X, y, y_pred)\"\\n')\n",
    "    return [pred_train, pred_test, X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "639f3776",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file = r'E:\\OneDrive\\Arbeit\\Repos\\DMC2022\\Kevin\\csv\\09_orders_noItemsNotOrdered_evalCats_diffToNxtPurch.csv'\n",
    "\n",
    "columns = ['date',\n",
    "           'userID', \n",
    "           'itemID',\n",
    "           'nextBuyInDays',\n",
    "           'nextBuyInWeeks',\n",
    "           'order', \n",
    "           'brand', \n",
    "           'feature_1', \n",
    "           'feature_2', \n",
    "           'feature_3', \n",
    "           'feature_4', \n",
    "           'feature_5'\n",
    "          ]\n",
    "\n",
    "dtype = {'userID':np.uint32,\n",
    "         'itemID':np.uint32,\n",
    "         'nextBuyInDays':np.uint16,\n",
    "         'nextBuyInWeeks':np.uint8,\n",
    "         'order':np.uint8,\n",
    "         'brand':np.int16,\n",
    "         'feature_1':np.int8,\n",
    "         'feature_2':np.uint8,\n",
    "         'feature_3':np.int16,\n",
    "         'feature_4':np.int8,\n",
    "         'feature_5':np.int16}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7e4b1d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334934bd",
   "metadata": {},
   "source": [
    "# Predicting Days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746956c9",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f724795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 29.64 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file, usecols=columns, sep='|', dtype=dtype, nrows=None, converters={'date':pd.to_datetime})\n",
    "show_mem_usage(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433021ea",
   "metadata": {},
   "source": [
    "Creating additional time related features out of 'date' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb9d12c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['weekOfYear'] = df['date'].dt.weekofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18d3e2d",
   "metadata": {},
   "source": [
    "Drop the label that is NOT needed. Then append label column at end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79a860f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['nextBuyInWeeks'], axis=0, inplace=True)\n",
    "col = df.pop(\"nextBuyInDays\") # target variable\n",
    "df.insert(len(df.columns), col.name, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acb1d9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataframe...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b = [\n",
    "    '2020-06-01', # start train set\n",
    "    '2020-10-31', # end train set\n",
    "    '2020-11-01', # start test set\n",
    "    '2020-11-30'  # end test set\n",
    "    ]\n",
    "X_train, y_train, X_test, y_test = dt_train_test_split(df, b[0], b[1], b[2], b[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd8d398",
   "metadata": {},
   "source": [
    "## Training & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62ff62dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression    \n",
      "row count of set:\t\t\t\t\t 130779\n",
      "rows where label is not 0:\t\t\t\t 16281 \t (12.449 % of all rows in set)\n",
      "rows where label was predicted correctly AND not 0:\t 0 \t (0.000 % of rows where label is not 0)\n",
      "\n",
      "DecisionTreeClassifier\n",
      "row count of set:\t\t\t\t\t 130779\n",
      "rows where label is not 0:\t\t\t\t 16281 \t (12.449 % of all rows in set)\n",
      "rows where label was predicted correctly AND not 0:\t 86 \t (0.528 % of rows where label is not 0)\n",
      "\n",
      "KNeighborsClassifier  \n",
      "row count of set:\t\t\t\t\t 130779\n",
      "rows where label is not 0:\t\t\t\t 16281 \t (12.449 % of all rows in set)\n",
      "rows where label was predicted correctly AND not 0:\t 38 \t (0.233 % of rows where label is not 0)\n",
      "\n",
      "RandomForestClassifier\n",
      "row count of set:\t\t\t\t\t 130779\n",
      "rows where label is not 0:\t\t\t\t 16281 \t (12.449 % of all rows in set)\n",
      "rows where label was predicted correctly AND not 0:\t 34 \t (0.209 % of rows where label is not 0)\n",
      "\n",
      "GaussianNB            \n",
      "row count of set:\t\t\t\t\t 130779\n",
      "rows where label is not 0:\t\t\t\t 16281 \t (12.449 % of all rows in set)\n",
      "rows where label was predicted correctly AND not 0:\t 0 \t (0.000 % of rows where label is not 0)\n",
      "\n",
      "MLPClassifier         \n",
      "row count of set:\t\t\t\t\t 130779\n",
      "rows where label is not 0:\t\t\t\t 16281 \t (12.449 % of all rows in set)\n",
      "rows where label was predicted correctly AND not 0:\t 0 \t (0.000 % of rows where label is not 0)\n",
      "\n",
      "XGBClassifier         \n",
      "row count of set:\t\t\t\t\t 130779\n",
      "rows where label is not 0:\t\t\t\t 16281 \t (12.449 % of all rows in set)\n",
      "rows where label was predicted correctly AND not 0:\t 52 \t (0.319 % of rows where label is not 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import ensemble, preprocessing, tree\n",
    "from sklearn.metrics import auc, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from yellowbrick.classifier import ConfusionMatrix, ROCAUC\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "\n",
    "for model in [LogisticRegression, DecisionTreeClassifier, KNeighborsClassifier, RandomForestClassifier, GaussianNB, MLPClassifier, XGBClassifier]:\n",
    "    cls = model()\n",
    "    fitted_model = cls.fit(X_train, y_train)\n",
    "    pred_train = cls.predict(X_train)\n",
    "    pred_test = cls.predict(X_test)\n",
    "    \n",
    "    df_eval_train = evaluate_pred(X_train, y_train, pred_train)\n",
    "    df_eval_test = evaluate_pred(X_test, y_test, pred_test)\n",
    "    \n",
    "    rowcount = len(df_eval_test)\n",
    "    should = len(df_eval_test.loc[(df_eval_test.nextBuyInDays != 0)])\n",
    "    is_ = len(df_eval_test.loc[(df_eval_test.nextBuyInDays != 0) & (df_eval_test.nextBuyInDays == df_eval_test.nextBuyIn_pred)]) \n",
    "\n",
    "    print(f'{model.__name__:22}')\n",
    "    print(f'row count of set:\\t\\t\\t\\t\\t {rowcount}')\n",
    "    print(f'rows where label is not 0:\\t\\t\\t\\t {should} \\t ({should/rowcount*100:.3f} % of all rows in set)')\n",
    "    print(f'rows where label was predicted correctly AND not 0:\\t {is_} \\t ({is_/should*100:.3f} % of rows where label is not 0)')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332cd51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4850745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe81ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc60cb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43479987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "47bec3b1",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import ensemble, preprocessing, tree\n",
    "from sklearn.metrics import auc, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from yellowbrick.classifier import ConfusionMatrix, ROCAUC\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "\n",
    "for model in [DecisionTreeClassifier]:\n",
    "    cls = model()\n",
    "    #kfold = model_selection.KFold(n_splits=10)\n",
    "    #s = model_selection.cross_val_score(cls, X, y, scoring='roc_auc')\n",
    "\n",
    "    #print(\n",
    "    #    f\"{model.__name__:22} AUC: \"\n",
    "    #    f\"{s.mean():.3f}\"\n",
    "    #)\n",
    "    \n",
    "#recall_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b453b4f",
   "metadata": {},
   "source": [
    "# Predicting Weeks"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e648bd6d",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "daba3971",
   "metadata": {},
   "source": [
    "df = pd.read_csv(file, usecols=columns, sep='|', dtype=dtype, nrows=None, converters={'date':pd.to_datetime})\n",
    "show_mem_usage(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ddb346f4",
   "metadata": {},
   "source": [
    "Creating additional time related features out of 'date' column."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a110e20b",
   "metadata": {},
   "source": [
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['weekOfYear'] = df['date'].dt.weekofyear"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf7123d1",
   "metadata": {},
   "source": [
    "Drop the label that is NOT needed. Then append label column at end."
   ]
  },
  {
   "cell_type": "raw",
   "id": "946bd96e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df.drop(columns=['nextBuyInDays'], axis=0, inplace=True)\n",
    "col = df.pop(\"nextBuyInWeeks\") # target variable\n",
    "df.insert(len(df.columns), col.name, col)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d71d12d",
   "metadata": {},
   "source": [
    "## Training & Prediction"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfe79b5d",
   "metadata": {},
   "source": [
    "Pipeline needs training method, dataframe and dates to split dataframe in training and test set."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c02246c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%%time\n",
    "pred_train, pred_test, X_train, y_train, X_test, y_test = execute_pipeline(train_xgb, df, [\n",
    "    '2020-06-01', # start train set\n",
    "    '2020-10-31', # end train set\n",
    "    '2020-11-01', # start test set\n",
    "    '2020-11-30'  # end test set\n",
    "])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0577c94",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0679e95",
   "metadata": {},
   "source": [
    "### train set"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7cee3cd0",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "df_eval_train = evaluate_pred(X_train, y_train, pred_train)\n",
    "df_eval_train.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3d28a01",
   "metadata": {},
   "source": [
    "### test set"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d70f8ed",
   "metadata": {},
   "source": [
    "df_eval_test = evaluate_pred(X_test, y_test, pred_test)\n",
    "df_eval_test.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14a72b8d",
   "metadata": {},
   "source": [
    "rowcount = len(df_eval_test)\n",
    "should = len(df_eval_test.loc[(df_eval_test.nextBuyInWeeks != 0)])\n",
    "is_ = len(df_eval_test.loc[(df_eval_test.nextBuyInWeeks != 0) & (df_eval_test.nextBuyInWeeks == df_eval_test.nextBuyIn_pred)]) \n",
    "\n",
    "print(f'row count of set:\\t\\t\\t\\t\\t {rowcount}')\n",
    "print(f'rows where label is not 0:\\t\\t\\t\\t {should} \\t ({should/rowcount*100:.3f} % of all rows in set)')\n",
    "print(f'rows where label was predicted correctly AND not 0:\\t {is_} \\t ({is_/should*100:.3f} % of rows where label is not 0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49edaf3d",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
