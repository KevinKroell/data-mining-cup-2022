{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe6e8b87",
   "metadata": {},
   "source": [
    "# Model Comparison, no categories, with dates, including \"onetimers\"\n",
    "## Predicting the time difference to the next repurchase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01cce02",
   "metadata": {},
   "source": [
    "### Methods & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c992df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import joblib\n",
    "import hyperopt\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_rows', 250)\n",
    "pd.set_option('display.min_rows', 25)\n",
    "\n",
    "####\n",
    "# prints memory usage\n",
    "def show_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB\\n'.format(start_mem))\n",
    "    return\n",
    "\n",
    "####\n",
    "# seperates features from label (y must be last column)\n",
    "def sep_X_y(df_train, df_test):\n",
    "    X_train = df_train.iloc[:,0:-1] # extracts all rows [:] and columns from 0 to next-to-last [0:-1]\n",
    "    y_train = df_train.iloc[:,-1] # extracts all rows [:] and only last column [-1]\n",
    "    X_test = df_test.iloc[:,0:-1]\n",
    "    y_test = df_test.iloc[:,-1]\n",
    "    \n",
    "    return [X_train, y_train, X_test, y_test]\n",
    "\n",
    "####\n",
    "# split training and test set from given dataframe with dates as boundaries\n",
    "def dt_train_test_split(df, dt_start_train, dt_end_train, dt_start_test, dt_end_test):\n",
    "    print('Splitting dataframe...\\n')\n",
    "    # get indices from desired boundaries\n",
    "    idx_start_train = df.date.searchsorted(pd.to_datetime(dt_start_train), side='left') # list needs to be sorted already for searchsorted\n",
    "    idx_end_train = df.date.searchsorted(pd.to_datetime(dt_end_train) + pd.Timedelta(days=1), side='left')\n",
    "    idx_start_test = df.date.searchsorted(pd.to_datetime(dt_start_test), side='left')\n",
    "    idx_end_test = df.date.searchsorted(pd.to_datetime(dt_end_test) + pd.Timedelta(days=1), side='left')\n",
    "    \n",
    "    train = df.iloc[idx_start_train:idx_end_train]\n",
    "    test = df.iloc[idx_start_test:idx_end_test]\n",
    "    \n",
    "    train.drop(columns=['date'], axis=0, inplace=True)\n",
    "    test.drop(columns=['date'], axis=0, inplace=True)\n",
    "    \n",
    "    return sep_X_y(train, test)\n",
    "\n",
    "####\n",
    "# trains XGB model (classifier)\n",
    "def train_xgb(X, y):\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    \n",
    "    print('Fitting model...\\n')\n",
    "    model = XGBClassifier(tree_method='gpu_hist', gpu_id=0)\n",
    "    fitted_model = model.fit(X_train, y_train)\n",
    "    \n",
    "    print('Plotting feature importance for \"gain\". Do not rely on that.\\n')\n",
    "    print('https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27\\n')\n",
    "    xgb.plot_importance(model, importance_type='gain')\n",
    "    plt.show()\n",
    "    \n",
    "    # GRAPHVIZ (software + pip package) needed for tree plotting\n",
    "    #fig, ax = plt.subplots(figsize=(30, 30))\n",
    "    #xgb.plot_tree(model, num_trees=0, ax=ax, rankdir='LR')\n",
    "    #plt.show()\n",
    "    \n",
    "    return fitted_model\n",
    "\n",
    "####\n",
    "# predicts labels of training and test with given model\n",
    "def predict_values(model, X_train, y_train, X_test, y_test):\n",
    "    print('Predicting values...\\n')\n",
    "    # predict y values\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    \n",
    "    # get accuracies\n",
    "    model_train = accuracy_score(y_train, y_train_pred)\n",
    "    model_test = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #get precision\n",
    "    model_train_precision = precision_score(y_train, y_train_pred, average)\n",
    "    model_test_precision = precision_score(y_test, y_test_pred)\n",
    "    \"\"\"\n",
    "    # print info about accuracies\n",
    "    print(f'\\n XGboost train/test accuracies: '\n",
    "         f'{model_train:.3f}/{model_test:.3f}')\n",
    "    \n",
    "    # return predicted values\n",
    "    return [y_train_pred, y_test_pred]\n",
    "\n",
    "####\n",
    "# concatenates prediction with actual target for evaluation\n",
    "def evaluate_pred(X, y, y_pred):\n",
    "    # create dataframe from test-prediction with index from X_test\n",
    "    df_y_pred = pd.DataFrame(y_pred, columns=['nextBuyIn_pred'], index=X.index, dtype=np.int32)\n",
    "\n",
    "    # concatenate X, y, y_pred (put columns next to each other)\n",
    "    df_eval = pd.concat([X, y, df_y_pred], axis=1)\n",
    "    \n",
    "    return df_eval\n",
    "\n",
    "####\n",
    "# executes all needed functions of the above with given training and test data and provided train method\n",
    "def execute_pipeline(train_method, df, list_of_four_df_boundaries):\n",
    "    b = list_of_four_df_boundaries\n",
    "    # split dataframe in train/test and X/y\n",
    "    X_train, y_train, X_test, y_test = dt_train_test_split(df, b[0], b[1], b[2], b[3])\n",
    "    \n",
    "    #train model\n",
    "    model = train_method(X_train, y_train)    \n",
    "    \n",
    "    # make predictions\n",
    "    pred_train, pred_test = predict_values(model, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print('\\nExecuted pipeline.\\nEvaluate with \"evaluate_pred(X, y, y_pred)\"\\n')\n",
    "    return [pred_train, pred_test, X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "639f3776",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file = r'E:\\OneDrive\\Arbeit\\Repos\\DMC2022\\Kevin\\csv\\09_orders_noItemsNotOrdered_evalCats_diffToNxtPurch.csv'\n",
    "\n",
    "columns = ['date',\n",
    "           'userID', \n",
    "           'itemID',\n",
    "           'nextBuyInDays',\n",
    "           'nextBuyInWeeks',\n",
    "           'order', \n",
    "           'brand', \n",
    "           'feature_1', \n",
    "           'feature_2', \n",
    "           'feature_3', \n",
    "           'feature_4', \n",
    "           'feature_5'\n",
    "          ]\n",
    "\n",
    "dtype = {'userID':np.uint32,\n",
    "         'itemID':np.uint32,\n",
    "         'nextBuyInDays':np.uint16,\n",
    "         'nextBuyInWeeks':np.uint8,\n",
    "         'order':np.uint8,\n",
    "         'brand':np.int16,\n",
    "         'feature_1':np.int8,\n",
    "         'feature_2':np.uint8,\n",
    "         'feature_3':np.int16,\n",
    "         'feature_4':np.int8,\n",
    "         'feature_5':np.int16}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7e4b1d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334934bd",
   "metadata": {},
   "source": [
    "# Predicting Days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746956c9",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f724795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 29.64 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file, usecols=columns, sep='|', dtype=dtype, nrows=None, converters={'date':pd.to_datetime})\n",
    "show_mem_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c457036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doubling\n",
    "df_dbl = df.copy()\n",
    "df_cpy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ab2d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df,df_cpy], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4af585cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>nextBuyInDays</th>\n",
       "      <th>nextBuyInWeeks</th>\n",
       "      <th>order</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>4</td>\n",
       "      <td>18860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>603</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>536</td>\n",
       "      <td>3</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076412</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>43855</td>\n",
       "      <td>26798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1232</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076411</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>43855</td>\n",
       "      <td>26239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>219</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>536</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076410</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>43855</td>\n",
       "      <td>20843</td>\n",
       "      <td>235</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>1324</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>356</td>\n",
       "      <td>3</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076409</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>43855</td>\n",
       "      <td>8350</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1232</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076408</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>43855</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1206</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>421</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076407</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>43781</td>\n",
       "      <td>20562</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076406</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>43736</td>\n",
       "      <td>25075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>319</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076405</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>43736</td>\n",
       "      <td>17269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>829</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076404</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>43736</td>\n",
       "      <td>3971</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>291</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076403</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>43730</td>\n",
       "      <td>20138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1445</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076402</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>43730</td>\n",
       "      <td>18003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1445</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069095</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>30718</td>\n",
       "      <td>21862</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>716</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>531</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069096</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>30718</td>\n",
       "      <td>21910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>872</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069097</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>30718</td>\n",
       "      <td>23531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1130</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>472</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069098</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>30718</td>\n",
       "      <td>24299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>514</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>377</td>\n",
       "      <td>3</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069099</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>30718</td>\n",
       "      <td>29492</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>408</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>503</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069100</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>30718</td>\n",
       "      <td>29560</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1445</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069101</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>30718</td>\n",
       "      <td>31354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>469</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069102</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>30727</td>\n",
       "      <td>15163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>378</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>396</td>\n",
       "      <td>3</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069103</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>30727</td>\n",
       "      <td>16165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>827</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>377</td>\n",
       "      <td>-1</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069104</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>30727</td>\n",
       "      <td>20664</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>408</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069106</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>30742</td>\n",
       "      <td>16260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143075</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>46137</td>\n",
       "      <td>22583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>449</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2143076 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  userID  itemID  nextBuyInDays  nextBuyInWeeks  order  \\\n",
       "0       2020-06-01       4   18860              0               0      1   \n",
       "1076412 2020-06-01   43855   26798              0               0      1   \n",
       "1076411 2020-06-01   43855   26239              0               0      2   \n",
       "1076410 2020-06-01   43855   20843            235              34      2   \n",
       "1076409 2020-06-01   43855    8350              0               0      1   \n",
       "1076408 2020-06-01   43855     217              0               0      2   \n",
       "1076407 2020-06-01   43781   20562             22               3      3   \n",
       "1076406 2020-06-01   43736   25075              0               0      1   \n",
       "1076405 2020-06-01   43736   17269              0               0      3   \n",
       "1076404 2020-06-01   43736    3971              0               0      1   \n",
       "1076403 2020-06-01   43730   20138              0               0      1   \n",
       "1076402 2020-06-01   43730   18003              0               0      2   \n",
       "...            ...     ...     ...            ...             ...    ...   \n",
       "1069095 2021-01-31   30718   21862              0               0      3   \n",
       "1069096 2021-01-31   30718   21910              0               0      3   \n",
       "1069097 2021-01-31   30718   23531              0               0      1   \n",
       "1069098 2021-01-31   30718   24299              0               0      1   \n",
       "1069099 2021-01-31   30718   29492              0               0      1   \n",
       "1069100 2021-01-31   30718   29560              0               0      1   \n",
       "1069101 2021-01-31   30718   31354              0               0      3   \n",
       "1069102 2021-01-31   30727   15163              0               0      1   \n",
       "1069103 2021-01-31   30727   16165              0               0      1   \n",
       "1069104 2021-01-31   30727   20664              0               0      1   \n",
       "1069106 2021-01-31   30742   16260              0               0      1   \n",
       "2143075 2021-01-31   46137   22583              0               0      1   \n",
       "\n",
       "         brand  feature_1  feature_2  feature_3  feature_4  feature_5  \n",
       "0          603         10          0        536          3        147  \n",
       "1076412   1232          6          0        282          0        146  \n",
       "1076411    219         10          1        536          0        156  \n",
       "1076410   1324          6          0        356          3         98  \n",
       "1076409   1232          4          0        358          0        117  \n",
       "1076408   1206         10          0        421          0          3  \n",
       "1076407     18          4          1        335          0        132  \n",
       "1076406    319          4          0        514          0        187  \n",
       "1076405    829          6          0         48          3         48  \n",
       "1076404     18          4          0        291          0         44  \n",
       "1076403   1445          4          3         -1         -1         -1  \n",
       "1076402   1445          4          0         -1         -1         -1  \n",
       "...        ...        ...        ...        ...        ...        ...  \n",
       "1069095    716          1          1        531          0         -1  \n",
       "1069096    872         10          0        491          0        156  \n",
       "1069097   1130          4          1        472          0         -1  \n",
       "1069098    514          4          0        377          3        176  \n",
       "1069099    408         10          0        503          0        123  \n",
       "1069100   1445          3          0         -1         -1         -1  \n",
       "1069101    105          4          0        469          0         -1  \n",
       "1069102    378          4          3        396          3        163  \n",
       "1069103    827         10          0        377         -1        121  \n",
       "1069104    408          4          0        284          0         66  \n",
       "1069106     70          4          0        491          3         74  \n",
       "2143075    449          6          0        179          0        122  \n",
       "\n",
       "[2143076 rows x 12 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433021ea",
   "metadata": {},
   "source": [
    "Creating additional time related features out of 'date' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb9d12c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['weekOfYear'] = df['date'].dt.weekofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18d3e2d",
   "metadata": {},
   "source": [
    "Drop the label that is NOT needed. Then append label column at end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79a860f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['nextBuyInWeeks'], axis=0, inplace=True)\n",
    "col = df.pop(\"nextBuyInDays\") # target variable\n",
    "df.insert(len(df.columns), col.name, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acb1d9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataframe...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b = [\n",
    "    '2020-06-01', # start train set\n",
    "    '2020-10-31', # end train set\n",
    "    '2020-11-01', # start test set\n",
    "    '2020-11-30'  # end test set\n",
    "    ]\n",
    "X_train, y_train, X_test, y_test = dt_train_test_split(df, b[0], b[1], b[2], b[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd8d398",
   "metadata": {},
   "source": [
    "## Training & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62ff62dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "row count of set:\t\t\t\t\t 130779\n",
      "rows where label is not 0:\t\t\t\t 16281 \t (12.449 % of all rows in set)\n",
      "rows where label was predicted correctly AND not 0:\t 91 \t (0.559 % of rows where label is not 0)\n",
      "\n",
      "XGBClassifier         \n",
      "row count of set:\t\t\t\t\t 130779\n",
      "rows where label is not 0:\t\t\t\t 16281 \t (12.449 % of all rows in set)\n",
      "rows where label was predicted correctly AND not 0:\t 52 \t (0.319 % of rows where label is not 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import ensemble, preprocessing, tree\n",
    "from sklearn.metrics import auc, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from yellowbrick.classifier import ConfusionMatrix, ROCAUC\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "\n",
    "for model in [DecisionTreeClassifier, XGBClassifier]:\n",
    "    cls = model()\n",
    "    fitted_model = cls.fit(X_train, y_train)\n",
    "    pred_train = cls.predict(X_train)\n",
    "    pred_test = cls.predict(X_test)\n",
    "    \n",
    "    df_eval_train = evaluate_pred(X_train, y_train, pred_train)\n",
    "    df_eval_test = evaluate_pred(X_test, y_test, pred_test)\n",
    "    \n",
    "    rowcount = len(df_eval_test)\n",
    "    should = len(df_eval_test.loc[(df_eval_test.nextBuyInDays != 0)])\n",
    "    is_ = len(df_eval_test.loc[(df_eval_test.nextBuyInDays != 0) & (df_eval_test.nextBuyInDays == df_eval_test.nextBuyIn_pred)]) \n",
    "\n",
    "    print(f'{model.__name__:22}')\n",
    "    print(f'row count of set:\\t\\t\\t\\t\\t {rowcount}')\n",
    "    print(f'rows where label is not 0:\\t\\t\\t\\t {should} \\t ({should/rowcount*100:.3f} % of all rows in set)')\n",
    "    print(f'rows where label was predicted correctly AND not 0:\\t {is_} \\t ({is_/should*100:.3f} % of rows where label is not 0)')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4850745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe81ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc60cb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43479987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "47bec3b1",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import ensemble, preprocessing, tree\n",
    "from sklearn.metrics import auc, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from yellowbrick.classifier import ConfusionMatrix, ROCAUC\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "\n",
    "for model in [DecisionTreeClassifier]:\n",
    "    cls = model()\n",
    "    #kfold = model_selection.KFold(n_splits=10)\n",
    "    #s = model_selection.cross_val_score(cls, X, y, scoring='roc_auc')\n",
    "\n",
    "    #print(\n",
    "    #    f\"{model.__name__:22} AUC: \"\n",
    "    #    f\"{s.mean():.3f}\"\n",
    "    #)\n",
    "    \n",
    "#recall_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b453b4f",
   "metadata": {},
   "source": [
    "# Predicting Weeks"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e648bd6d",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "daba3971",
   "metadata": {},
   "source": [
    "df = pd.read_csv(file, usecols=columns, sep='|', dtype=dtype, nrows=None, converters={'date':pd.to_datetime})\n",
    "show_mem_usage(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ddb346f4",
   "metadata": {},
   "source": [
    "Creating additional time related features out of 'date' column."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a110e20b",
   "metadata": {},
   "source": [
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['weekOfYear'] = df['date'].dt.weekofyear"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf7123d1",
   "metadata": {},
   "source": [
    "Drop the label that is NOT needed. Then append label column at end."
   ]
  },
  {
   "cell_type": "raw",
   "id": "946bd96e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df.drop(columns=['nextBuyInDays'], axis=0, inplace=True)\n",
    "col = df.pop(\"nextBuyInWeeks\") # target variable\n",
    "df.insert(len(df.columns), col.name, col)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d71d12d",
   "metadata": {},
   "source": [
    "## Training & Prediction"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfe79b5d",
   "metadata": {},
   "source": [
    "Pipeline needs training method, dataframe and dates to split dataframe in training and test set."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c02246c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%%time\n",
    "pred_train, pred_test, X_train, y_train, X_test, y_test = execute_pipeline(train_xgb, df, [\n",
    "    '2020-06-01', # start train set\n",
    "    '2020-10-31', # end train set\n",
    "    '2020-11-01', # start test set\n",
    "    '2020-11-30'  # end test set\n",
    "])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0577c94",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0679e95",
   "metadata": {},
   "source": [
    "### train set"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7cee3cd0",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "df_eval_train = evaluate_pred(X_train, y_train, pred_train)\n",
    "df_eval_train.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3d28a01",
   "metadata": {},
   "source": [
    "### test set"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d70f8ed",
   "metadata": {},
   "source": [
    "df_eval_test = evaluate_pred(X_test, y_test, pred_test)\n",
    "df_eval_test.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14a72b8d",
   "metadata": {},
   "source": [
    "rowcount = len(df_eval_test)\n",
    "should = len(df_eval_test.loc[(df_eval_test.nextBuyInWeeks != 0)])\n",
    "is_ = len(df_eval_test.loc[(df_eval_test.nextBuyInWeeks != 0) & (df_eval_test.nextBuyInWeeks == df_eval_test.nextBuyIn_pred)]) \n",
    "\n",
    "print(f'row count of set:\\t\\t\\t\\t\\t {rowcount}')\n",
    "print(f'rows where label is not 0:\\t\\t\\t\\t {should} \\t ({should/rowcount*100:.3f} % of all rows in set)')\n",
    "print(f'rows where label was predicted correctly AND not 0:\\t {is_} \\t ({is_/should*100:.3f} % of rows where label is not 0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49edaf3d",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
