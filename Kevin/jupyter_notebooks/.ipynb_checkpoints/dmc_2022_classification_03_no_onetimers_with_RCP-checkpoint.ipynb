{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b1bb5b5",
   "metadata": {},
   "source": [
    "# DMC 2022\n",
    "### Predicting user-based replenishment of a product based on historical orders and item features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e4147",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22289e4b",
   "metadata": {},
   "source": [
    "## 1. Task\n",
    "\n",
    "The participating teams’ goal is to predict the user-based replenishment of a product based on\n",
    "historical orders and item features. Individual items and user specific orders are given for the period\n",
    "between 01.06.2020 and 31.01.2021. The prediction period is between 01.02.2021 and 28.02.2021,\n",
    "which is exactly four weeks long.\n",
    "For a predefined subset of user and product combinations, the participants shall predict if and when\n",
    "a product will be purchased during the prediction period.\n",
    "The prediction column in the “submission.csv” file must be filled accordingly.\n",
    "* 0 - no replenishment during that period\n",
    "* 1 - replenishment in the first week\n",
    "* 2 - replenishment in the second week\n",
    "* 3 - replenishment in the third week\n",
    "* 4 - replenishment in the fourth week"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e1a48b",
   "metadata": {},
   "source": [
    "## 2. Problem Definition\n",
    "\n",
    "The problem we will be exploring is **multiclass classification**. Based on a number of different features we are trying to predict whether a product will be replenished by a certain customer in a specific week 1-4 or not at all 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48283c10",
   "metadata": {},
   "source": [
    "## 3. Tools we are going to use\n",
    "\n",
    "* [pandas](https://pandas.pydata.org/) for data analysis and data manipulation\n",
    "* [Knime](https://www.knime.com/) for data analysis (outside of this notebook)\n",
    "* [NumPy](https://numpy.org/) for numerical operations\n",
    "* [Matplotlib](https://matplotlib.org/) for visualization\n",
    "* [Scikit-Learn](https://scikit-learn.org/stable/) for machine learning modeling and evaluation\n",
    "* [XGBoost](https://xgboost.readthedocs.io/en/stable/) for gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633d2bee",
   "metadata": {},
   "source": [
    "## 4. Features\n",
    "\n",
    "1. date\n",
    "2. userID\n",
    "3. itemID\n",
    "4. order\n",
    "5. brand\n",
    "6. feature_1\n",
    "7. feature_2\n",
    "8. feature_3\n",
    "9. feature_4\n",
    "10. feature_5\n",
    "11. categories\n",
    "12. week\n",
    "\n",
    "#### Not used\n",
    "13. RCP\n",
    "14. parent_category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47210ab",
   "metadata": {},
   "source": [
    "## Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0751b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import gc\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def show_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4677c738",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "639f3776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 42.56 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>order</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>categories</th>\n",
       "      <th>week</th>\n",
       "      <th>RCP</th>\n",
       "      <th>Mean(date&amp;time diff)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>29737</td>\n",
       "      <td>5237</td>\n",
       "      <td>1</td>\n",
       "      <td>1201</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "      <td>[327, 3129, 414, 4206]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.266990</td>\n",
       "      <td>41.227027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>29737</td>\n",
       "      <td>11535</td>\n",
       "      <td>3</td>\n",
       "      <td>328</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>498</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>[715, 3267]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>36.329897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>13081</td>\n",
       "      <td>16536</td>\n",
       "      <td>1</td>\n",
       "      <td>615</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>[390, 2080, 536, 1708]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>50.378378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>19712</td>\n",
       "      <td>15299</td>\n",
       "      <td>2</td>\n",
       "      <td>1023</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>503</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>[3672, 1091, 1085, 1578, 2325]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>45.744681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>19712</td>\n",
       "      <td>26623</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>528</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>[2019, 1633, 482]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>34083</td>\n",
       "      <td>18169</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>421</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[2116, 3224, 3156, 2690]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.233503</td>\n",
       "      <td>44.677966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>23038</td>\n",
       "      <td>31567</td>\n",
       "      <td>1</td>\n",
       "      <td>408</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>334</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>[1711, 2621, 2919]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.188073</td>\n",
       "      <td>32.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>40277</td>\n",
       "      <td>30133</td>\n",
       "      <td>1</td>\n",
       "      <td>408</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>334</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>[1711, 2621, 2919, 3924, 3915, 3914]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.266026</td>\n",
       "      <td>39.968468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>29971</td>\n",
       "      <td>8793</td>\n",
       "      <td>1</td>\n",
       "      <td>990</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>474</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>[3867, 1998, 3025, 46, 3649, 3915, 3914]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>48.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>22109</td>\n",
       "      <td>8004</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>[2977, 1772, 1118, 4025, 4026]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090032</td>\n",
       "      <td>43.764706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  userID  itemID  order  brand  feature_1  feature_2  feature_3  \\\n",
       "0  2020-06-01   29737    5237      1   1201         10          0         53   \n",
       "1  2020-06-01   29737   11535      3    328          4          0        498   \n",
       "2  2020-06-01   13081   16536      1    615         10          0          6   \n",
       "3  2020-06-01   19712   15299      2   1023         10          0        503   \n",
       "4  2020-06-01   19712   26623      3     38         10          0        528   \n",
       "5  2020-06-01   34083   18169      1     73         10          0        421   \n",
       "6  2020-06-01   23038   31567      1    408          4          0        334   \n",
       "7  2020-06-01   40277   30133      1    408          4          0        334   \n",
       "8  2020-06-01   29971    8793      1    990          4          0        474   \n",
       "9  2020-06-01   22109    8004      1      6          6          0        303   \n",
       "\n",
       "   feature_4  feature_5                                categories  week  \\\n",
       "0          3         87                    [327, 3129, 414, 4206]     1   \n",
       "1          3         13                               [715, 3267]     1   \n",
       "2          0         84                    [390, 2080, 536, 1708]     1   \n",
       "3          0         17            [3672, 1091, 1085, 1578, 2325]     1   \n",
       "4          0        132                         [2019, 1633, 482]     1   \n",
       "5          3          3                  [2116, 3224, 3156, 2690]     1   \n",
       "6          0         44                        [1711, 2621, 2919]     1   \n",
       "7          0         44      [1711, 2621, 2919, 3924, 3915, 3914]     1   \n",
       "8          0      65535  [3867, 1998, 3025, 46, 3649, 3915, 3914]     1   \n",
       "9          3         45            [2977, 1772, 1118, 4025, 4026]     1   \n",
       "\n",
       "        RCP  Mean(date&time diff)  \n",
       "0  0.266990             41.227027  \n",
       "1  0.158333             36.329897  \n",
       "2  0.111111             50.378378  \n",
       "3  0.262500             45.744681  \n",
       "4  0.024390             27.000000  \n",
       "5  0.233503             44.677966  \n",
       "6  0.188073             32.577465  \n",
       "7  0.266026             39.968468  \n",
       "8  0.142857             48.785714  \n",
       "9  0.090032             43.764706  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#file1 = r'E:\\OneDrive\\Arbeit\\Repos\\DMC2022\\Kevin\\csv\\06_complete_dataset_labeled_week0.csv'\n",
    "\n",
    "file1 = r'E:\\OneDrive\\Arbeit\\Repos\\DMC2022\\Kevin\\csv\\07_complete_dataset_labeled_noOnetimers_RCP.csv'\n",
    "df_data = pd.read_csv(file1, sep='|', dtype={'userID':np.uint32,\n",
    "                                            'date':str, \n",
    "                                            'itemID':np.uint32,\n",
    "                                            'order':np.uint8,\n",
    "                                            'brand':np.uint16,\n",
    "                                            'feature_1':np.uint8,\n",
    "                                            'feature_2':np.uint8,\n",
    "                                            'feature_3':np.uint16,\n",
    "                                            'feature_4':np.uint8,\n",
    "                                            'feature_5':np.uint16,\n",
    "                                            'week':np.uint8})\n",
    "                     #chunksize=10000)\n",
    "\n",
    "show_mem_usage(df_data)\n",
    "df_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4145c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.drop('lastPurchaseDate', axis=1, inplace=True)\n",
    "df_data.drop('purchaseDates', axis=1, inplace=True)\n",
    "df_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f51f41",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dab4c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_data = df_data.sort_values('date')\n",
    "df_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0707e656",
   "metadata": {},
   "source": [
    "### Multi-Hot-Encoding for categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f47bda7",
   "metadata": {},
   "source": [
    "In contrast to One-Hot-Encoding where a column contains a single value which is converted to a one in the respective column, Multi-Hot-Encoding converts multiple entries in one cell to multiple ones in different columns. Therefore we first have to process the string in our category column, such that we can convert it into columns, without having duplicates.\n",
    "\n",
    "#### Memory problem after Multi-Hot-Encoding\n",
    "The problem we face when Multi-Hot-Encoding our categories is the following: After preprocessing and encoding we have 3.040.458.033 data points (904091 rows × 3363 columns). When trying to encode our categories with the str.get_dummies() method the size of the resulting dataframe is about ~30 GB depending on how many rows and features we are using. With a dataframe this big we run into memory problems when processing our data and building our model. \n",
    "\n",
    "#### Solution\n",
    "There are are couple of different solutions to work around this problem. Normally we could work around memory limiations using batch processing or external memory. In case of the DMC dataset this is not optimal, since we need the whole customer history to make accurate predictions.\n",
    "\n",
    "Since most of the colums we create from Multi-Hot-Encoding will be filled with zeros, we will be using a sparse matrix to significantly reduce the size of the resulting dataframe. The reduction we achieve with this approach results in dataframe size of 113 MB instead of ~30 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf7c8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert strings to lists of integers in 'categories'\n",
    "df_cat = df_data\n",
    "\n",
    "df_cat[\"categories\"] = df_cat[\"categories\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "df_cat[\"categories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5eafe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multi-Hot-Encode columns with sparse output\n",
    "c = df_cat[\"categories\"]\n",
    "mlb = MultiLabelBinarizer(sparse_output=False) # Set to True if output binary array is desired in CSR sparse format\n",
    "df_multi_hot = pd.DataFrame(mlb.fit_transform(c), columns=mlb.classes_, index=None, dtype=np.int8)\n",
    "\n",
    "show_mem_usage(df_multi_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6b4caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to sparse type\n",
    "sparse_df_mh = df_multi_hot.astype(pd.SparseDtype(\"float64\",0))\n",
    "print(sparse_df_mh.info())\n",
    "sparse_df_mh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96798bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_multi_hot\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb87a56b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Combine df_data and sparse_df_mh\n",
    "df_combined = df_cat.join(sparse_df_mh, how='inner')\n",
    "show_mem_usage(df_combined)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a053b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop and append 'week' at end of dataframe\n",
    "col = df_combined.pop(\"week\")\n",
    "df_combined.insert(len(df_combined.columns), col.name, col)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6259a0db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check if we have any missing values\n",
    "df_combined[df_combined.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc8760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.drop('categories', axis=1, inplace=True)\n",
    "show_mem_usage(df_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e6f8b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1e5d9c",
   "metadata": {},
   "source": [
    "### Splitting Training- / Testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ef120",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_combined.copy()\n",
    "id(df), id(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d22bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b1478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9712bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index of first occurance of january date for split\n",
    "idx = df.date.searchsorted('2021-01-01', side='left') # list needs to be sorted already for searchsorted\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70888f95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check index\n",
    "df['date'][idx], df['date'][idx - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6c0c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop date\n",
    "df.drop('date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159825cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Comma is being used to extract a specific column from a 2D array.\n",
    "# X = data.iloc[:,:-1]\n",
    "# X = all rows, all columns except the last one \n",
    "\n",
    "X = df.iloc[:,0:-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a24a6d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y = df.iloc[:,-1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c3d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training/test data\n",
    "# train = jun-dec20 / test = jan21\n",
    "\n",
    "X_train = X.iloc[:idx-1]\n",
    "X_test = X.iloc[idx:]\n",
    "y_train = y.iloc[:idx-1]\n",
    "y_test = y.iloc[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69445ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f42568b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_mem_usage(X_train), show_mem_usage(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8cd5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a5d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test data\n",
    "# parameter will preserve the proportion of target as in original dataset, in the train and test datasets as well.\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, stratify=y)\n",
    "\n",
    "#show_mem_usage(X_train), show_mem_usage(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046b60ef",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47b9f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5bfc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier = classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebf341e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier.score(X_train,y_train), classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504e313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = classifier.predict(X_train)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "\n",
    "dct_train = accuracy_score(y_train, y_train_pred)\n",
    "dct_test = accuracy_score(y_test, y_test_pred)\n",
    "print()\n",
    "print(f'Decision Tree train/test accuracies: '\n",
    "     f'{dct_train:.3f}/{dct_test:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7205e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = list(y_test_pred)\n",
    "y_test2 = list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5c9569",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_test)):\n",
    "    print(y_test2[i],y_prediction[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7e4d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cdc248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model1 = XGBClassifier()\n",
    "\n",
    "gbm = model1.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = gbm.predict(X_train)\n",
    "y_test_pred = gbm.predict(X_test)\n",
    "\n",
    "xgb_train = accuracy_score(y_train, y_train_pred)\n",
    "xgb_test = accuracy_score(y_test, y_test_pred)\n",
    "print()\n",
    "print(f'XGboost train/test accuracies: '\n",
    "     f'{xgb_train:.3f}/{xgb_test:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5ea029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
