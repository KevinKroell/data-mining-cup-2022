{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4gB3il3kP5l",
    "outputId": "c0149756-08a3-453f-c5f5-69d310651d6d"
   },
   "outputs": [],
   "source": [
    "#!python -m pip install numpy scipy matplotlib ipython jupyter pandas sympy nose\n",
    "#!pip install -U scikit-learn\n",
    "#!pip install xgboost\n",
    "#!pip install pyarrow\n",
    "#!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "DlyetB_ElFdz",
    "outputId": "29dfd8a7-8141-4221-9691-8c592df1a6b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import joblib\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_rows', 250)\n",
    "pd.set_option('display.min_rows', 25)\n",
    "\n",
    "####\n",
    "# Plays sinus\n",
    "def playSound():\n",
    "    from IPython.lib.display import Audio\n",
    "    framerate = 4410\n",
    "    play_time_seconds = 3\n",
    "\n",
    "    t = np.linspace(0, play_time_seconds, framerate*play_time_seconds)\n",
    "    audio_data = np.sin(2*np.pi*300*t) + np.sin(2*np.pi*200*t)\n",
    "    return Audio(audio_data, rate=framerate, autoplay=True) # plays 3sec sound, when done\n",
    "    \n",
    "\n",
    "####\n",
    "# prints memory usage\n",
    "def show_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB\\n'.format(start_mem))\n",
    "    return\n",
    "\n",
    "####\n",
    "# seperates features from label (y must be last column)\n",
    "def sep_X_y(df_train, df_test):\n",
    "    X_train = df_train.iloc[:,0:-1] # extracts all rows [:] and columns from 0 to next-to-last [0:-1]\n",
    "    y_train = df_train.iloc[:,-1] # extracts all rows [:] and only last column [-1]\n",
    "    X_test = df_test.iloc[:,0:-1]\n",
    "    y_test = df_test.iloc[:,-1]\n",
    "    \n",
    "    return [X_train, y_train, X_test, y_test]\n",
    "\n",
    "####\n",
    "# split training and test set from given dataframe with dates as boundaries\n",
    "def dt_train_test_split(df, dt_start_train, dt_end_train, dt_start_test, dt_end_test):\n",
    "    print('Splitting dataframe...\\n')\n",
    "    # get indices from desired boundaries\n",
    "    idx_start_train = df.date.searchsorted(pd.to_datetime(dt_start_train), side='left') # list needs to be sorted already for searchsorted\n",
    "    idx_end_train = df.date.searchsorted(pd.to_datetime(dt_end_train) + pd.Timedelta(days=1), side='left')\n",
    "    idx_start_test = df.date.searchsorted(pd.to_datetime(dt_start_test), side='left')\n",
    "    idx_end_test = df.date.searchsorted(pd.to_datetime(dt_end_test) + pd.Timedelta(days=1), side='left')\n",
    "    \n",
    "    train = df.iloc[idx_start_train:idx_end_train]\n",
    "    test = df.iloc[idx_start_test:idx_end_test]\n",
    "    \n",
    "    train.drop(columns=['date'], axis=0, inplace=True)\n",
    "    test.drop(columns=['date'], axis=0, inplace=True)\n",
    "    \n",
    "    return sep_X_y(train, test)\n",
    "\n",
    "####\n",
    "# trains XGB model (classifier)\n",
    "def train_xgb(X, y):\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    \n",
    "    print('Fitting model...\\n')\n",
    "    model = XGBClassifier(tree_method='gpu_hist', gpu_id=0)\n",
    "    fitted_model = model.fit(X_train, y_train)\n",
    "    \n",
    "    print('Plotting feature importance for \"gain\". Do not rely on that.\\n')\n",
    "    print('https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27\\n')\n",
    "    xgb.plot_importance(model, importance_type='gain')\n",
    "    plt.show()\n",
    "    \n",
    "    # GRAPHVIZ (software + pip package) needed for tree plotting\n",
    "    #fig, ax = plt.subplots(figsize=(30, 30))\n",
    "    #xgb.plot_tree(model, num_trees=0, ax=ax, rankdir='LR')\n",
    "    #plt.show()\n",
    "    \n",
    "    return fitted_model\n",
    "\n",
    "####\n",
    "# predicts labels of training and test with given model\n",
    "def predict_values(model, X_train, y_train, X_test, y_test):\n",
    "    print('Predicting values...\\n')\n",
    "    # predict y values\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # get accuracies\n",
    "    model_train = accuracy_score(y_train, y_train_pred)\n",
    "    model_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    # print info about accuracies\n",
    "    print(f'\\n XGboost train/test accuracies: '\n",
    "         f'{model_train:.3f}/{model_test:.3f}')\n",
    "    \n",
    "    # return predicted values\n",
    "    return [y_train_pred, y_test_pred]\n",
    "\n",
    "####\n",
    "# concatenates prediction with actual target for evaluation\n",
    "def evaluate_pred(X, y, y_pred):\n",
    "    # create dataframe from test-prediction with index from X_test\n",
    "    df_y_pred = pd.DataFrame(y_pred, columns=['nextBuyIn_pred'], index=X.index, dtype=np.int8)\n",
    "\n",
    "    # concatenate X, y, y_pred (put columns next to each other)\n",
    "    df_eval = pd.concat([X, y, df_y_pred], axis=1)\n",
    "    \n",
    "    return df_eval\n",
    "\n",
    "####\n",
    "# executes all needed functions of the above with given training and test data and provided train method\n",
    "def execute_pipeline(train_method, df, list_of_four_df_boundaries):\n",
    "    b = list_of_four_df_boundaries\n",
    "    # split dataframe in train/test and X/y\n",
    "    X_train, y_train, X_test, y_test = dt_train_test_split(df, b[0], b[1], b[2], b[3])\n",
    "    \n",
    "    #train model\n",
    "    model = train_method(X_train, y_train)    \n",
    "    \n",
    "    # make predictions\n",
    "    pred_train, pred_test = predict_values(model, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print('\\nExecuted pipeline.\\nEvaluate with \"evaluate_pred(X, y, y_pred)\"\\n')\n",
    "    return [pred_train, pred_test, X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCPu_SFMmf7G",
    "outputId": "9ac0f03c-88d1-4d7d-fdc5-e963de86af1d"
   },
   "outputs": [],
   "source": [
    "#Connect Google Drive to Google Colab\n",
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!mkdir /content/parquet/\n",
    "!cp /content/drive/MyDrive/parquet/220621_02_everyCombinationPerDay_basicFeatures_labeled_XTest.parquet /content/parquet/220621_02_everyCombinationPerDay_basicFeatures_labeled_XTest.parquet\n",
    "!cp /content/drive/MyDrive/parquet/220621_02_everyCombinationPerDay_basicFeatures_labeled_XTrain.parquet /content/parquet/220621_02_everyCombinationPerDay_basicFeatures_labeled_XTrain.parquet\n",
    "!cp /content/drive/MyDrive/parquet/220621_02_everyCombinationPerDay_basicFeatures_labeled_yTest.parquet /content/parquet/220621_02_everyCombinationPerDay_basicFeatures_labeled_yTest.parquet\n",
    "!cp /content/drive/MyDrive/parquet/220621_02_everyCombinationPerDay_basicFeatures_labeled_yTrain.parquet /content/parquet/220621_02_everyCombinationPerDay_basicFeatures_labeled_yTrain.parquet\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YlwPM4LBlOi_",
    "outputId": "370eec04-c2e3-4d65-b5ff-99b6f01524e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 33 s\n",
      "Wall time: 6.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_xtrain = r'E:\\OneDrive\\Arbeit\\Repos\\DMC2022\\Kevin\\csv\\220621_02_everyCombinationPerDay_basicFeatures_labeled_XTrain.parquet'\n",
    "path_ytrain = r'E:\\OneDrive\\Arbeit\\Repos\\DMC2022\\Kevin\\csv\\220621_02_everyCombinationPerDay_basicFeatures_labeled_yTrain.parquet'\n",
    "path_xtest = r'E:\\OneDrive\\Arbeit\\Repos\\DMC2022\\Kevin\\csv\\220621_02_everyCombinationPerDay_basicFeatures_labeled_XTest.parquet'\n",
    "path_ytest = r'E:\\OneDrive\\Arbeit\\Repos\\DMC2022\\Kevin\\csv\\220621_02_everyCombinationPerDay_basicFeatures_labeled_yTest.parquet'\n",
    "\n",
    "X_train = pd.read_parquet(path_xtrain, engine='pyarrow')\n",
    "y_train = pd.read_parquet(path_ytrain, engine='pyarrow')\n",
    "X_test = pd.read_parquet(path_xtest, engine='pyarrow')\n",
    "y_test = pd.read_parquet(path_ytest, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_Nz-pWaoDZQ",
    "outputId": "a5dda7b1-6fd1-44ff-ca56-20028c1538c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[20:35:41] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_gpu_hist.cu:712: Exception in gpu_hist: [20:35:41] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: bad allocation: cudaErrorMemoryAllocation: out of memory\n- Free memory: 1389494272\n- Requested memory: 2451629456\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mtrain_xgb\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFitting model...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     79\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBClassifier(tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_hist\u001b[39m\u001b[38;5;124m'\u001b[39m, gpu_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 80\u001b[0m fitted_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlotting feature importance for \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgain\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Do not rely on that.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\xgboost\\core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    531\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\xgboost\\sklearn.py:1400\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1379\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(\n\u001b[0;32m   1380\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1381\u001b[0m )\n\u001b[0;32m   1382\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1383\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1384\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1397\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_categorical,\n\u001b[0;32m   1398\u001b[0m )\n\u001b[1;32m-> 1400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\xgboost\\core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    531\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\xgboost\\core.py:1733\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1733\u001b[0m     \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1734\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1735\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1737\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\xgboost\\core.py:203\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [20:35:41] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_gpu_hist.cu:712: Exception in gpu_hist: [20:35:41] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: bad allocation: cudaErrorMemoryAllocation: out of memory\n- Free memory: 1389494272\n- Requested memory: 2451629456\n\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = train_xgb(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqzWxPs5oLor",
    "outputId": "3822f747-2209-4542-f616-c31dca8af06a"
   },
   "outputs": [],
   "source": [
    "pred_train, pred_test = predict_values(model, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "220619_03_XGB_GPU_every-day_wEveryCombination.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
